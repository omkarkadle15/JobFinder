#!/bin/bash

# Start the Ollama model server
ollama serve --model llama3.1